{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10405de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built interactive figure.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Scrollable 4-panel figure (shared time axis):\n",
    "(1) 13–30 Hz band-passed LFP (chan48, 500 Hz) + Hilbert envelope\n",
    "(2) Delta, Low-beta, High-beta band power\n",
    "(3) Center-of-mass (Snout/Tail average) speed from DLC\n",
    "(4) Spike raster limited to last strobe time\n",
    "\n",
    "Outputs: an interactive HTML (zoom/pan/scroll) saved next to this script.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "\n",
    "# ----------------------------\n",
    "# Paths (edit if your mount differs)\n",
    "# ----------------------------\n",
    "BASE = Path(\"/Volumes/Extreme SSD/Neuropixels/9153_02072025_tagging_g0/9153_02072025_tagging_g0_imec0/kilosort4\")\n",
    "LFP_PATH = BASE / \"lfp_chan48_500Hz.npy\"\n",
    "BANDS_NPZ = BASE / \"alignment_amp_tailAccel_02072025.npz\"\n",
    "SPIKE_SECONDS_PATH = BASE / \"spike_seconds_adj.npy\"      # REQUIRED: times (float64, 1-D)\n",
    "SPIKE_UNIT_IDS_PATH = BASE / \"spike_clusters.npy\"        # OPTIONAL: per-spike unit ids (1-D int), same length as times\n",
    "QMETRICS_TSV = (BASE.parent / \"kilosort4qMetrics\" / \"templates._bc_unit_labels.tsv\")\n",
    "CLASS_CSV = BASE / \"unit_classification_rulebased.csv\"\n",
    "STROBE_PATH = BASE / \"strobe_seconds.npy\"\n",
    "EXPORT_STATIC = True\n",
    "STATIC_PNG = BASE / \"scrollable_4panel_02072025.png\"\n",
    "STATIC_PDF = BASE / \"scrollable_4panel_02072025.pdf\"\n",
    "STATIC_WIDTH = 12000   # pixels (keep < 65000)\n",
    "STATIC_HEIGHT = 1400   # pixels\n",
    "\n",
    "DLC_H5 = Path(\"/Volumes/Extreme SSD/Neuropixels/DLC/9153/9153_Day13_4rewards2025-02-07T13_43_04DLC_HrnetW32_Neuropixel_9153Jun23shuffle1_detector_230_snapshot_210.h5\")\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "FS_LFP = 500.0                          # Hz (for lfp_chan48_500Hz.npy)\n",
    "BETA_BAND = (13.0, 30.0)                # band-pass for beta\n",
    "SMOOTH_SPEED_SEC = 0.10                 # ~100 ms moving-average on speed (DLC)\n",
    "STANDARDIZE_BANDS = True                # z-score delta/low-beta/high-beta for plotting\n",
    "STANDARDIZE_SPEED = True                # z-score COM speed for plotting\n",
    "HTML_OUT = BASE / \"scrollable_4panel_02072025.html\"\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def zscore(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.nanmean(x)\n",
    "    s = np.nanstd(x)\n",
    "    if s == 0 or not np.isfinite(s):\n",
    "        s = 1.0\n",
    "    return (x - m) / s\n",
    "\n",
    "def bandpass_filt(x, fs, lo, hi, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    b, a = butter(order, [lo/nyq, hi/nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "def moving_average(x, win_samples):\n",
    "    if win_samples <= 1:\n",
    "        return x\n",
    "    kernel = np.ones(win_samples, dtype=float) / win_samples\n",
    "    return np.convolve(x, kernel, mode=\"same\")\n",
    "\n",
    "def build_dlc_timebase_from_strobe(strobe_seconds, n_rows):\n",
    "    # Interpolate *evenly* from first → last strobe to DLC rows\n",
    "    return np.linspace(strobe_seconds[0], strobe_seconds[-1], n_rows)\n",
    "\n",
    "def extract_xy_from_dlc(df, bodypart, scorer=None):\n",
    "    \"\"\"\n",
    "    DLC pandas HDF is usually MultiIndex (scorer, bodypart, coord).\n",
    "    Returns x,y arrays (float). Raises if missing.\n",
    "    \"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        if scorer is None:\n",
    "            scorer = sorted(set([c[0] for c in df.columns]))[0]\n",
    "        cols = ( (scorer, bodypart, \"x\"), (scorer, bodypart, \"y\") )\n",
    "        if all(c in df.columns for c in cols):\n",
    "            x = df[cols[0]].astype(float).to_numpy()\n",
    "            y = df[cols[1]].astype(float).to_numpy()\n",
    "            return x, y\n",
    "        else:\n",
    "            raise KeyError(f\"Bodypart {bodypart} with scorer {scorer} missing x/y columns.\")\n",
    "    else:\n",
    "        # Single-level fallback (rare)\n",
    "        xcol = f\"{bodypart}_x\"\n",
    "        ycol = f\"{bodypart}_y\"\n",
    "        x = df[xcol].astype(float).to_numpy()\n",
    "        y = df[ycol].astype(float).to_numpy()\n",
    "        return x, y\n",
    "\n",
    "def robust_group_spikes(times_path, unit_ids_path=None, good_units=None, msn_units=None, tmax=None):\n",
    "    \"\"\"\n",
    "    Group spikes into (unit_id, spike_times) pairs.\n",
    "    - Accepts times-only (falls back to single-row raster).\n",
    "    - If unit_ids_path is provided but lengths differ, truncates BOTH arrays to the common min length.\n",
    "    - Clips to tmax (e.g., last strobe) BEFORE grouping.\n",
    "    - Applies optional filters: good_units and msn_units.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # Load spike times\n",
    "    times = np.load(times_path, allow_pickle=True).astype(float).ravel()\n",
    "    times = times[np.isfinite(times)]\n",
    "\n",
    "    # If we don't have unit IDs, return a single-row raster (times only)\n",
    "    if unit_ids_path is None or not Path(unit_ids_path).exists():\n",
    "        if tmax is not None:\n",
    "            times = times[times <= tmax]\n",
    "        return [(-1, np.sort(times))]\n",
    "\n",
    "    # Load per-spike unit IDs\n",
    "    units = np.load(unit_ids_path, allow_pickle=True).astype(int).ravel()\n",
    "\n",
    "    # --- HANDLE LENGTH MISMATCH BY TRUNCATING TO COMMON MIN LENGTH ---\n",
    "    if len(units) != len(times):\n",
    "        n = min(len(units), len(times))\n",
    "        print(f\"WARNING: spike_clusters length ({len(units)}) != spike_seconds length ({len(times)}). \"\n",
    "              f\"Truncating to first {n} entries.\")\n",
    "        units = units[:n]\n",
    "        times = times[:n]\n",
    "\n",
    "    # Clip to tmax first (so raster is limited to last strobe)\n",
    "    if tmax is not None:\n",
    "        m = times <= tmax\n",
    "        times = times[m]\n",
    "        units = units[m]\n",
    "\n",
    "    # Group by unit id\n",
    "    buckets = defaultdict(list)\n",
    "    for u, t in zip(units, times):\n",
    "        if np.isfinite(t):\n",
    "            buckets[int(u)].append(float(t))\n",
    "\n",
    "    # Convert to arrays and apply filters (good + MSN)\n",
    "    grouped = []\n",
    "    for u in sorted(buckets.keys()):\n",
    "        if (good_units is not None) and (u not in good_units):\n",
    "            continue\n",
    "        if (msn_units is not None) and (u not in msn_units):\n",
    "            continue\n",
    "        arr = np.sort(np.asarray(buckets[u], dtype=float))\n",
    "        if arr.size:\n",
    "            grouped.append((u, arr))\n",
    "\n",
    "    # If filtering removed everything, fall back to unfiltered units (so you still see something)\n",
    "    if not grouped:\n",
    "        grouped = [(u, np.sort(np.asarray(buckets[u], dtype=float))) for u in sorted(buckets.keys()) if len(buckets[u])]\n",
    "\n",
    "    return grouped\n",
    "\n",
    "# ----------------------------\n",
    "# 1) LFP 13–30 Hz with envelope\n",
    "# ----------------------------\n",
    "lfp = np.load(LFP_PATH).astype(float)  # 1D, 500 Hz\n",
    "lfp_filt = bandpass_filt(lfp, FS_LFP, BETA_BAND[0], BETA_BAND[1])\n",
    "lfp_env = np.abs(hilbert(lfp_filt))\n",
    "\n",
    "# 2) Band power (delta/low-beta/high-beta)\n",
    "bands = np.load(BANDS_NPZ)\n",
    "time_lfp = bands[\"time_lfp\"].astype(float)\n",
    "\n",
    "def get_npz_key(npz, candidates):\n",
    "    for k in candidates:\n",
    "        if k in npz.files:\n",
    "            return k\n",
    "    raise KeyError(f\"None of keys {candidates} found in NPZ. Available: {list(npz.files)}\")\n",
    "\n",
    "delta_key = get_npz_key(bands, [\"delta_amp\", \"delta\", \"delta_power\"])\n",
    "blo_key   = get_npz_key(bands, [\"beta_low_amp\", \"low_beta_amp\", \"beta_low\"])\n",
    "bhi_key   = get_npz_key(bands, [\"beta_high_amp\", \"high_beta_amp\", \"beta_high\"])\n",
    "\n",
    "delta = bands[delta_key].astype(float)\n",
    "beta_low = bands[blo_key].astype(float)\n",
    "beta_high = bands[bhi_key].astype(float)\n",
    "\n",
    "if len(time_lfp) == len(lfp):\n",
    "    t_lfp = time_lfp\n",
    "else:\n",
    "    t_lfp = np.linspace(time_lfp[0], time_lfp[-1], len(lfp))\n",
    "\n",
    "if STANDARDIZE_BANDS:\n",
    "    delta_p = zscore(delta)\n",
    "    blo_p = zscore(beta_low)\n",
    "    bhi_p = zscore(beta_high)\n",
    "else:\n",
    "    delta_p, blo_p, bhi_p = delta, beta_low, beta_high\n",
    "\n",
    "# 3) Center-of-mass speed from DLC (Snout/Tail average), DLC time from strobe\n",
    "dlc_df = pd.read_hdf(DLC_H5)\n",
    "n_rows = len(dlc_df)\n",
    "strobe = np.load(STROBE_PATH).astype(float)\n",
    "t_dlc = build_dlc_timebase_from_strobe(strobe, n_rows)\n",
    "dt_dlc = float(np.median(np.diff(t_dlc)))\n",
    "t_last_strobe = float(strobe[-1])\n",
    "\n",
    "snout_x, snout_y = extract_xy_from_dlc(dlc_df, \"Snout\")\n",
    "try:\n",
    "    tail_x, tail_y = extract_xy_from_dlc(dlc_df, \"Tail\")\n",
    "except Exception:\n",
    "    tail_x = tail_y = None\n",
    "    for alt in [\"TailBase\", \"Tailbase\", \"TailTip\", \"Tail_tip\"]:\n",
    "        try:\n",
    "            tail_x, tail_y = extract_xy_from_dlc(dlc_df, alt)\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "if tail_x is None:\n",
    "    raise RuntimeError(\"No Tail-like bodypart found in DLC file.\")\n",
    "\n",
    "def clean_interp(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    a[a <= -0.5] = np.nan\n",
    "    return pd.Series(a).interpolate(limit_direction=\"both\").to_numpy()\n",
    "\n",
    "snout_x, snout_y = clean_interp(snout_x), clean_interp(snout_y)\n",
    "tail_x, tail_y   = clean_interp(tail_x),   clean_interp(tail_y)\n",
    "\n",
    "com_x = 0.5 * (snout_x + tail_x)\n",
    "com_y = 0.5 * (snout_y + tail_y)\n",
    "\n",
    "vx = np.gradient(com_x, t_dlc)\n",
    "vy = np.gradient(com_y, t_dlc)\n",
    "speed = np.sqrt(vx**2 + vy**2)\n",
    "\n",
    "# Smooth ~100 ms\n",
    "win = max(3, int(round(SMOOTH_SPEED_SEC / max(dt_dlc, 1e-9))))\n",
    "if win % 2 == 0:\n",
    "    win += 1\n",
    "kernel = np.ones(win)/win\n",
    "speed_s = np.convolve(speed, kernel, mode=\"same\")\n",
    "\n",
    "speed_plot = zscore(speed_s) if STANDARDIZE_SPEED else speed_s\n",
    "\n",
    "# 4) Spike raster limited to last strobe time; group by unit if possible\n",
    "# \"good\" labels (1/2) and MSN only, if available\n",
    "good_units = None\n",
    "try:\n",
    "    qm = pd.read_csv(QMETRICS_TSV, sep=\"\\t\")\n",
    "    # Adjust column names if yours differ:\n",
    "    good_units = set(qm[\"unitType\"].isin([1, 2]).index.astype(int)).tolist()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "msn_units = None\n",
    "try:\n",
    "    uclass = pd.read_csv(CLASS_CSV)\n",
    "    msn_units = set(uclass.loc[uclass[\"cell_type\"].str.upper()==\"MSN\", \"unit_id\"].astype(int).tolist())\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "spikes_kept = robust_group_spikes(SPIKE_SECONDS_PATH, SPIKE_UNIT_IDS_PATH if SPIKE_UNIT_IDS_PATH.exists() else None,\n",
    "                                  good_units=good_units, msn_units=msn_units, tmax=t_last_strobe)\n",
    "\n",
    "# ----------------------------\n",
    "# Build interactive, shared-x figure (Plotly)\n",
    "# ----------------------------\n",
    "fig = make_subplots(rows=4, cols=1, shared_xaxes=True, vertical_spacing=0.03,\n",
    "                    row_heights=[0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# (1) LFP filter and envelope\n",
    "fig.add_trace(go.Scatter(x=t_lfp, y=lfp_filt, name=\"13–30 Hz LFP\", line=dict(width=1)),\n",
    "              row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=t_lfp, y=lfp_env, name=\"Envelope\", line=dict(width=1)),\n",
    "              row=1, col=1)\n",
    "\n",
    "# (2) Band powers\n",
    "fig.add_trace(go.Scatter(x=time_lfp, y=delta_p, name=\"Delta\"), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=time_lfp, y=blo_p,   name=\"Low beta\"), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=time_lfp, y=bhi_p,   name=\"High beta\"), row=2, col=1)\n",
    "\n",
    "# (3) COM speed\n",
    "fig.add_trace(go.Scatter(x=t_dlc, y=speed_plot, name=\"COM speed\"), row=3, col=1)\n",
    "\n",
    "# (4) Spike raster (units stacked or single row)\n",
    "if len(spikes_kept) == 1 and spikes_kept[0][0] == -1:\n",
    "    # single-row fallback\n",
    "    times = spikes_kept[0][1]\n",
    "    fig.add_trace(go.Scatter(x=times, y=np.ones_like(times), mode=\"markers\",\n",
    "                             marker=dict(size=2), name=\"All spikes ≤ last strobe\"),\n",
    "                  row=4, col=1)\n",
    "    fig.update_yaxes(range=[0.5, 1.5], title_text=\"All spikes\", row=4, col=1)\n",
    "else:\n",
    "    # multi-unit raster: offset each unit on the y-axis\n",
    "    y_offset = 0\n",
    "    for uid, times in spikes_kept:\n",
    "        y = np.full_like(times, y_offset + 1.0, dtype=float)\n",
    "        fig.add_trace(go.Scatter(x=times, y=y, mode=\"markers\",\n",
    "                         marker=dict(size=2, color=\"black\"),\n",
    "                         name=f\"u{uid}\", showlegend=False),\n",
    "              row=4, col=1)\n",
    "        y_offset += 1\n",
    "    fig.update_yaxes(range=[0, y_offset + 1], title_text=\"Unit (good & MSN)\", row=4, col=1)\n",
    "\n",
    "# Shared x axis, wide layout (scroll/zoom via Plotly UI)\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    "    width=2400,   # big canvas; zoom/pan for more detail\n",
    "    title_text=\"Scrollable 4-panel (shared x, spikes ≤ last strobe)\",\n",
    "    hovermode=\"x unified\",\n",
    ")\n",
    "print(\"Built interactive figure.\")\n",
    "# Save static images (requires: pip install -U kaleido)\n",
    "if EXPORT_STATIC:\n",
    "    try:\n",
    "        import plotly.io as pio\n",
    "        # Share the same x-range up to last strobe for every subplot\n",
    "        t0 = min(t_lfp[0], time_lfp[0], t_dlc[0])\n",
    "        fig.update_xaxes(range=[t0, t_last_strobe])\n",
    "        fig.write_image(STATIC_PNG, width=STATIC_WIDTH, height=STATIC_HEIGHT, scale=1)\n",
    "        fig.write_image(STATIC_PDF, width=STATIC_WIDTH, height=STATIC_HEIGHT, scale=1)\n",
    "        print(f\"Saved {STATIC_PNG} and {STATIC_PDF}\")\n",
    "    except Exception as e:\n",
    "        print(\"Static export failed. Install kaleido:  pip install -U kaleido\")\n",
    "        raise\n",
    "\n",
    "# Axis labels\n",
    "fig.update_yaxes(title_text=\"LFP (a.u.)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Band power (z)\" if STANDARDIZE_BANDS else \"Band power\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"COM speed (z)\" if STANDARDIZE_SPEED else \"COM speed\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Time (s)\", row=4, col=1)\n",
    "\n",
    "# Save to HTML\n",
    "fig.write_html(HTML_OUT, include_plotlyjs=\"cdn\")\n",
    "print(f\"Saved interactive HTML: {HTML_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdabc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
