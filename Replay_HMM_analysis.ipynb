{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay, HMM on LFP, and Joint Spike–LFP–Behavior Features\n",
    "\n",
    "Skeleton implementations for the remaining TODO items:\n",
    "- Decode replay with place fields + shuffles\n",
    "- HMM on LFP bandpower\n",
    "- Joint spike–LFP–behavior feature extraction and clustering\n",
    "- Positional clustering of units\n",
    "- Real-time stimulation outline\n",
    "\n",
    "Edit paths below to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "try:\n",
    "    from hmmlearn import hmm\n",
    "    have_hmm = True\n",
    "except ImportError:\n",
    "    have_hmm = False\n",
    "    print(\"hmmlearn not installed; HMM cell will error unless installed.\")\n",
    "\n",
    "# Paths (edit)\n",
    "spikeglx_probe_folder = Path(r\"Z:\\Koji\\Neuropixels\\1818\\1818_11202025_g0\\1818_11202025_g0_imec0\")\n",
    "spike_dir = spikeglx_probe_folder / \"kilosort4\"\n",
    "spike_times_path = spike_dir / \"spike_seconds_adj.npy\"\n",
    "spike_clusters_path = spike_dir / \"spike_clusters.npy\"\n",
    "unit_labels_path = spike_dir / \"..\" / \"kilosort4qMetrics\" / \"templates._bc_unit_labels.tsv\"\n",
    "celltype_path = spike_dir / \"unit_classification_rulebased.csv\"\n",
    "spectrogram_meta = spikeglx_probe_folder / \"spectrogram_fullsession_meta.npz\"\n",
    "spectrogram_memmap = spikeglx_probe_folder / \"spectrogram_fullsession.dat\"\n",
    "\n",
    "# Behavior paths (edit if needed)\n",
    "event_csvs = [\n",
    "    Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise_corner_2025-11-20T15_11_30.csv\"),\n",
    "    Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise_licking_2025-11-20T15_11_30.csv\"),\n",
    "]\n",
    "dlc_csv = Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise2025-11-20T15_50_10DLC_HrnetW32_openfield_v3Sep10shuffle2_detector_170_snapshot_160.csv\")\n",
    "cam_fps = 60.0\n",
    "\n",
    "print(\"Paths set. Edit as needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spikes and metadata\n",
    "spike_times = np.load(spike_times_path)\n",
    "spike_clusters = np.load(spike_clusters_path)\n",
    "unit_labels = np.loadtxt(unit_labels_path, delimiter=\"\\t\", dtype=int)\n",
    "good_units = unit_labels == 1\n",
    "celltypes = {}\n",
    "if celltype_path.exists():\n",
    "    import pandas as pd\n",
    "    df_ct = pd.read_csv(celltype_path)\n",
    "    celltypes = dict(zip(df_ct[\"cluster_id\"], df_ct[\"cell_type\"]))\n",
    "print(f\"Spikes: {spike_times.size}, units: {np.unique(spike_clusters).size}, good units: {good_units.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load behavior (DLC) and events\n",
    "dlc = pd.read_csv(dlc_csv, header=None)\n",
    "dlc_time_cam = np.arange(len(dlc)) / cam_fps\n",
    "events = pd.concat([pd.read_csv(p) for p in event_csvs], ignore_index=True)\n",
    "print(\"DLC shape:\", dlc.shape, \"Events shape:\", events.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment helper (camera time to NP time)\n",
    "Reuse the mapping from `Event_DLC_DA_alignment.ipynb` if available. Set `a_cam_np` and `b_cam_np` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mapping from camera time to NP time (t_np = a*t_cam + b)\n",
    "a_cam_np = None  # fill from alignment notebook\n",
    "b_cam_np = None\n",
    "\n",
    "def cam_to_np_time(cam_times):\n",
    "    if a_cam_np is None or b_cam_np is None:\n",
    "        raise RuntimeError(\"Set a_cam_np and b_cam_np from alignment notebook\")\n",
    "    return a_cam_np * np.asarray(cam_times) + b_cam_np\n",
    "\n",
    "dlc_time_np = cam_to_np_time(dlc_time_cam) if a_cam_np is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place fields and replay decoding (Bayesian skeleton)\n",
    "- Compute 1D position from DLC (choose a body part / axis)\n",
    "- Build tuning curves during movement\n",
    "- Decode position in candidate events and test vs shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tuning(pos, pos_time, spikes_s, spikes_clu, good_mask, nbins=50, speed=None, speed_thresh=2.0):\n",
    "    pos = np.asarray(pos)\n",
    "    pos_time = np.asarray(pos_time)\n",
    "    edges = np.linspace(pos.min(), pos.max(), nbins+1)\n",
    "    occ, _ = np.histogram(pos, bins=edges)\n",
    "    occ = occ / np.diff(pos_time).mean()  # occupancy in samples -> time\n",
    "    tc = {}\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    for uid, good in enumerate(good_mask):\n",
    "        if not good:\n",
    "            continue\n",
    "        st = spikes_s[spikes_clu == uid]\n",
    "        if speed is not None:\n",
    "            # keep spikes during movement\n",
    "            # approximate: mask by nearest position sample\n",
    "            st_mask = speed[np.clip((st / np.diff(pos_time).mean()).astype(int), 0, speed.size-1)] > speed_thresh\n",
    "            st = st[st_mask]\n",
    "        if st.size == 0:\n",
    "            continue\n",
    "        # bin spikes by position via interpolation\n",
    "        pos_at_spikes = np.interp(st, pos_time, pos)\n",
    "        spk_counts, _ = np.histogram(pos_at_spikes, bins=edges)\n",
    "        tc[uid] = (spk_counts + 1e-3) / (occ + 1e-3)  # FR estimate\n",
    "    return centers, tc\n",
    "\n",
    "def decode_position(tuning_curves, pos_bins, spike_bin_counts):\n",
    "    # spike_bin_counts: shape (n_units, n_timebins)\n",
    "    units = list(tuning_curves.keys())\n",
    "    lam = np.stack([tuning_curves[u] for u in units])  # (n_units, nbins)\n",
    "    dt = 0.02  # bin size (s) assumed\n",
    "    # Poisson likelihood\n",
    "    log_l = spike_bin_counts.T[:,:,None] * np.log(lam.T[None,:,:] + 1e-12) - dt * lam.T[None,:,:]\n",
    "    post = np.exp(log_l.sum(axis=1))\n",
    "    post /= post.sum(axis=1, keepdims=True)\n",
    "    return post  # (n_timebins, nbins)\n",
    "\n",
    "# Placeholder usage:\n",
    "# pos = dlc.iloc[:,0].values (choose appropriate body part/axis)\n",
    "# centers, tc = compute_tuning(pos, dlc_time_np, spike_times, spike_clusters, good_units)\n",
    "# Build spike counts in small bins during events, then decode_position(tc, centers, spike_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM on LFP bandpower\n",
    "- Extract bandpower features per channel (or PCA of channels)\n",
    "- Fit a Gaussian HMM to uncover latent LFP states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfp_bandpower_features(lfp_rec, bands, win_s=0.5, step_s=0.1, duration_s=300):\n",
    "    fs = lfp_rec.get_sampling_frequency()\n",
    "    n_frames = min(int(duration_s * fs), lfp_rec.get_num_frames())\n",
    "    win = int(win_s * fs)\n",
    "    step = max(1, int(step_s * fs))\n",
    "    feats = []\n",
    "    times = []\n",
    "    bs = [butter(4, [b[0]/(fs/2), b[1]/(fs/2)], btype='band') for b in bands]\n",
    "    for start in tqdm(range(0, n_frames - win + 1, step), desc=\"LFP bandpower feats\"):\n",
    "        end = start + win\n",
    "        x = lfp_rec.get_traces(start_frame=start, end_frame=end)\n",
    "        band_pwr = []\n",
    "        for b,a in bs:\n",
    "            xf = filtfilt(b,a,x,axis=0)\n",
    "            band_pwr.append(np.mean(xf**2, axis=0))\n",
    "        feats.append(np.hstack(band_pwr))\n",
    "        times.append(start/fs)\n",
    "    return np.asarray(times), np.vstack(feats)\n",
    "\n",
    "def fit_hmm_bandpower(features, n_states=3):\n",
    "    if not have_hmm:\n",
    "        raise RuntimeError(\"hmmlearn not installed\")\n",
    "    model = hmm.GaussianHMM(n_components=n_states, covariance_type='full', n_iter=100)\n",
    "    model.fit(features)\n",
    "    states = model.predict(features)\n",
    "    return model, states\n",
    "\n",
    "# Example (uncomment when ready):\n",
    "# bands = [(4,8),(13,30),(30,80)]\n",
    "# times_feat, feats = lfp_bandpower_features(lfp_rec, bands, win_s=0.5, step_s=0.1, duration_s=120)\n",
    "# model, states = fit_hmm_bandpower(feats, n_states=3)\n",
    "# plt.plot(times_feat, states); plt.title('LFP HMM states'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike–LFP–behavior joint features\n",
    "- Bin spikes, LFP bandpower, and DLC kinematics into a feature matrix\n",
    "- Cluster or classify to find motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_joint_features(spike_times_s, spike_clusters, good_units, lfp_rec, dlc_pos, dlc_time_np, bands, bin_s=0.05, duration_s=300):\n",
    "    fs = lfp_rec.get_sampling_frequency()\n",
    "    nbins = int(duration_s / bin_s)\n",
    "    t_bins = np.linspace(0, duration_s, nbins+1)\n",
    "    # spike bins (good units only)\n",
    "    units = np.where(good_units)[0]\n",
    "    spk_mat = np.zeros((nbins, len(units)))\n",
    "    for ui, u in enumerate(units):\n",
    "        st = spike_times_s[spike_clusters == u]\n",
    "        st = st[(st >= 0) & (st < duration_s)]\n",
    "        counts, _ = np.histogram(st, bins=t_bins)\n",
    "        spk_mat[:, ui] = counts / bin_s\n",
    "    # LFP bandpower per bin for channel 0 (extend as needed)\n",
    "    lfp = lfp_rec.get_traces(start_frame=0, end_frame=min(int(duration_s*fs), lfp_rec.get_num_frames()), channel_ids=[0])[:,0]\n",
    "    band_feats = []\n",
    "    for b in bands:\n",
    "        b_f, a_f = butter(4, [b[0]/(fs/2), b[1]/(fs/2)], btype='band')\n",
    "        lfpf = filtfilt(b_f, a_f, lfp)\n",
    "        amp = lfpf**2\n",
    "        # bin by time\n",
    "        t_lfp = np.arange(len(amp))/fs\n",
    "        bp, _ = np.histogram(t_lfp, bins=t_bins, weights=amp)\n",
    "        counts, _ = np.histogram(t_lfp, bins=t_bins)\n",
    "        bp = bp / (counts + 1e-6)\n",
    "        band_feats.append(bp)\n",
    "    band_feats = np.vstack(band_feats).T  # (nbins, nbands)\n",
    "    # Behavior: position and speed from DLC\n",
    "    pos_interp = np.interp((t_bins[:-1]+t_bins[1:])/2, dlc_time_np, dlc_pos)\n",
    "    speed = np.concatenate([[0], np.abs(np.diff(pos_interp)) / bin_s])\n",
    "    beh_feats = np.vstack([pos_interp, speed]).T\n",
    "    # Concatenate\n",
    "    feats = np.hstack([spk_mat, band_feats, beh_feats])\n",
    "    return t_bins[:-1], feats, units\n",
    "\n",
    "def cluster_features(feats, n_clusters=5):\n",
    "    gm = GaussianMixture(n_components=n_clusters, covariance_type='full', n_init=3)\n",
    "    labels = gm.fit_predict(feats)\n",
    "    return gm, labels\n",
    "\n",
    "# Example usage (requires dlc_time_np set):\n",
    "# t_feat, feats, units = build_joint_features(spike_times, spike_clusters, good_units, lfp_rec, dlc.iloc[:,0].values, dlc_time_np, bands=[(13,30),(30,80)], bin_s=0.05, duration_s=120)\n",
    "# gm, labels = cluster_features(feats, n_clusters=5)\n",
    "# plt.plot(t_feat, labels); plt.title('Joint feature clusters'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional clustering of units\n",
    "- Cluster units based on their place-field tuning (correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_place_fields(tuning_curves, n_clusters=4):\n",
    "    # tuning_curves: dict unit-> FR per bin\n",
    "    units = list(tuning_curves.keys())\n",
    "    if len(units) == 0:\n",
    "        return None, None\n",
    "    mat = np.stack([tuning_curves[u] for u in units])\n",
    "    # normalize\n",
    "    mat = (mat - mat.mean(axis=1, keepdims=True)) / (mat.std(axis=1, keepdims=True)+1e-6)\n",
    "    gm = GaussianMixture(n_components=n_clusters, covariance_type='full', n_init=3)\n",
    "    labels = gm.fit_predict(mat)\n",
    "    return dict(zip(units, labels)), gm\n",
    "\n",
    "# Example: after compute_tuning -> labels = cluster_place_fields(tc, n_clusters=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time stimulation outline (concept)\n",
    "- Implemented outside notebook in practice; here is pseudocode outline.\n",
    "- Steps:\n",
    "  1) Stream spikes from AP band (threshold/template) with low latency.\n",
    "  2) Detect pattern (e.g., high firing of specific units or phase-locked bursts).\n",
    "  3) Trigger DAQ line for optogenetic stim with safety limits.\n",
    "  4) Start with DAT-Cre for prototyping, then adapt to AnxA1-Cre.\n",
    "- Use a compiled/real-time environment (e.g., Open Ephys plugins or custom C++/Python with NI-DAQ)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
