{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event/DLC/DA Alignment Utilities\n",
    "\n",
    "This notebook provides reusable functions to:\n",
    "- Load event CSVs (camera-strobe aligned)\n",
    "- Load DeepLabCut (DLC) CSVs (60 Hz) and compute kinematics\n",
    "- Load DA (TDT) dFF and strobe\n",
    "- Load Neuropixels strobe\n",
    "- Compute alignment between strobe signals (DA ↔ NP ↔ camera) so everything shares a common time base\n",
    "\n",
    "Paths are prefilled for the 1818 dataset. Edit them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import correlate\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# ---- paths (edit as needed) ----\n",
    "event_csvs = [\n",
    "    Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise_corner_2025-11-20T15_11_30.csv\"),\n",
    "    Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise_licking_2025-11-20T15_11_30.csv\"),\n",
    "]\n",
    "dlc_csv = Path(r\"Z:\\Koji\\NP_Coh3\\Recording\\Day27_1818_Clockwise2025-11-20T15_50_10DLC_HrnetW32_openfield_v3Sep10shuffle2_detector_170_snapshot_160.csv\")\n",
    "da_mat = Path(r\"Z:\\Koji\\NP_Coh3\\TDT\\1818\\250919\\1818_250919_dFF.mat\")\n",
    "np_strobe_npy = Path(r\"Z:\\Koji\\Neuropixels\\1818\\1818_11202025_g0\\1818_11202025_g0_imec0\\kilosort4\\strobe_signal.npy\")  # derive per SpikeSorting notebook\n",
    "\n",
    "# camera frame rate\n",
    "cam_fps = 60.0\n",
    "\n",
    "print(\"Paths set. Edit above if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load events CSVs and merge\n",
    "def load_events(csv_paths):\n",
    "    dfs = []\n",
    "    for p in csv_paths:\n",
    "        df = pd.read_csv(p)\n",
    "        df[\"source_file\"] = p.name\n",
    "        dfs.append(df)\n",
    "    ev = pd.concat(dfs, ignore_index=True)\n",
    "    return ev\n",
    "\n",
    "events = load_events(event_csvs)\n",
    "print(\"Events loaded:\", events.shape)\n",
    "display(events.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DLC CSV (DeepLabCut)\n",
    "dlc = pd.read_csv(dlc_csv, header=None)\n",
    "# DLC formats vary; here assume standard DLC wide CSV with scorer/bodyparts likelihood triplets.\n",
    "# Extract time vector based on cam_fps.\n",
    "dlc_time = np.arange(len(dlc)) / cam_fps\n",
    "print(\"DLC loaded:\", dlc.shape, \"time span (s)\", dlc_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DA dFF and strobe from TDT mat\n",
    "da = loadmat(da_mat)\n",
    "# Inspect keys to locate signals\n",
    "print(\"DA mat keys:\", da.keys())\n",
    "# Example: dFF signal under key 'dff', strobe under 'strobe', sample rate under 'fs'\n",
    "da_dff = None\n",
    "da_strobe = None\n",
    "da_fs = None\n",
    "for k in da.keys():\n",
    "    if k.lower() == 'dff':\n",
    "        da_dff = np.asarray(da[k]).squeeze()\n",
    "    if 'strobe' in k.lower():\n",
    "        da_strobe = np.asarray(da[k]).squeeze()\n",
    "    if k.lower() == 'fs':\n",
    "        da_fs = float(np.asarray(da[k]).squeeze())\n",
    "print(\"DA signals: dff\", None if da_dff is None else da_dff.shape, \"strobe\", None if da_strobe is None else da_strobe.shape, \"fs\", da_fs)\n",
    "da_time = np.arange(len(da_dff)) / da_fs if da_dff is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Neuropixels strobe (pre-extracted). If not available, extract per SpikeSorting.ipynb guidance.\n",
    "np_strobe = np.load(np_strobe_npy) if np_strobe_npy.exists() else None\n",
    "print(\"NP strobe shape:\", None if np_strobe is None else np_strobe.shape)"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment helpers: detect strobe edges and build linear mapping between time bases\n",
    "def detect_strobe_edges(sig, fs, height=None, distance=None):\n",
    "    \"\"\"Return edge times (seconds) from a TTL-like strobe signal.\"\"\"\n",
    "    sig = np.asarray(sig).astype(float)\n",
    "    if height is None:\n",
    "        height = 0.5 * (sig.min() + sig.max())\n",
    "    if distance is None:\n",
    "        distance = max(1, int(0.5 * fs / cam_fps))  # at least ~half a frame apart\n",
    "    peaks, _ = find_peaks(sig, height=height, distance=distance)\n",
    "    return peaks / fs\n",
    "\n",
    "def fit_time_mapping(src_times, dst_times):\n",
    "    \"\"\"Linear mapping src->dst: dst = a*src + b using least squares.\"\"\"\n",
    "    src = np.asarray(src)\n",
    "    dst = np.asarray(dst)\n",
    "    a, b = np.polyfit(src, dst, 1)\n",
    "    return a, b\n",
    "\n",
    "def apply_mapping(times, a, b):\n",
    "    return a * np.asarray(times) + b\n",
    "\n",
    "# Build mappings if strobes are available\n",
    "mapping_cam_to_np = None\n",
    "mapping_da_to_np = None\n",
    "\n",
    "if np_strobe is not None:\n",
    "    # NP strobe edges (assume fs from LFP)\n",
    "    fs_np = None\n",
    "    try:\n",
    "        import spikeinterface.extractors as se\n",
    "        # fallback to using a small NP recording if needed; else assume 30k/1k depending on stream\n",
    "    except Exception:\n",
    "        pass\n",
    "    # If you know NP strobe fs, set fs_np here; otherwise assume 30000 for AP or 1000 for LF\n",
    "    fs_np = 1000.0\n",
    "    np_edges = detect_strobe_edges(np_strobe, fs=fs_np)\n",
    "\n",
    "    # Camera frame times (60 Hz) in camera time base\n",
    "    cam_times = np.arange(len(dlc_time)) / cam_fps if 'dlc_time' in locals() else None\n",
    "\n",
    "    if cam_times is not None and len(np_edges) >= len(cam_times):\n",
    "        # Align first len(cam_times) edges\n",
    "        cam_subset = cam_times\n",
    "        np_subset = np_edges[:len(cam_subset)]\n",
    "        a, b = fit_time_mapping(cam_subset, np_subset)\n",
    "        mapping_cam_to_np = (a, b)\n",
    "        print(f\"Camera->NP mapping: t_np = {a:.6f} * t_cam + {b:.6f}\")\n",
    "    else:\n",
    "        print(\"Not enough NP strobe edges to map camera frames; check strobe extraction.\")\n",
    "\n",
    "    if da_strobe is not None and da_fs is not None:\n",
    "        da_edges = detect_strobe_edges(da_strobe, fs=da_fs)\n",
    "        n_match = min(len(da_edges), len(np_edges))\n",
    "        if n_match > 5:\n",
    "            a, b = fit_time_mapping(da_edges[:n_match], np_edges[:n_match])\n",
    "            mapping_da_to_np = (a, b)\n",
    "            print(f\"DA->NP mapping: t_np = {a:.6f} * t_da + {b:.6f}\")\n",
    "        else:\n",
    "            print(\"Not enough overlapping strobe edges for DA->NP mapping.\")\n",
    "else:\n",
    "    print(\"NP strobe missing; cannot build mappings. Extract NP strobe per SpikeSorting.ipynb.\")"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper converters using fitted mappings\n",
    "def cam_to_np_time(cam_times):\n",
    "    if mapping_cam_to_np is None:\n",
    "        raise RuntimeError(\"Camera->NP mapping not available\")\n",
    "    a, b = mapping_cam_to_np\n",
    "    return apply_mapping(cam_times, a, b)\n",
    "\n",
    "def da_to_np_time(da_times):\n",
    "    if mapping_da_to_np is None:\n",
    "        raise RuntimeError(\"DA->NP mapping not available\")\n",
    "    a, b = mapping_da_to_np\n",
    "    return apply_mapping(da_times, a, b)\n",
    "\n",
    "# Example: align events and DLC to NP time\n",
    "if mapping_cam_to_np is not None:\n",
    "    cam_times = np.arange(len(dlc_time)) / cam_fps\n",
    "    dlc_time_np = cam_to_np_time(cam_times)\n",
    "    print(\"DLC time (NP base):\", dlc_time_np[:5], \"...\", dlc_time_np[-5:])\n",
    "    # If events have a 'frame' or 'time_cam' column, map it similarly:\n",
    "    # events['time_np'] = cam_to_np_time(events['frame'] / cam_fps)\n",
    "else:\n",
    "    print(\"Camera->NP mapping unavailable; cannot map DLC/events yet.\")\n",
    "\n",
    "print(\"Alignment helpers ready. Verify strobe extraction in DA_analysis.ipynb and SpikeSorting.ipynb if mappings fail.\")"
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
